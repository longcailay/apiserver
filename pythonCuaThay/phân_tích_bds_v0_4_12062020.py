# -*- coding: utf-8 -*-
"""Phân tích BDS v0.4_12062020.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AS6ZexgsQSZax4mPnJ2m4NbLVP3aJnlJ
"""

pip install xlsxwriter

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
# import matplotlib
import matplotlib.pyplot as plt
# import seaborn
import seaborn as sns
# %matplotlib inline
import math

#Write to excel file
import xlsxwriter
#Check file existe
import pathlib

"""# Read and Research Real Estate Data"""

from google.colab import drive
drive.mount('/content/drive')

"""#Define Parameters"""

#city_name="Đắk Lắk"
#district_name="Buôn Ma Thuột"
#Street_To_Study=''
#Category_To_Study='Bán đất'
#Category_To_Study='Bán đất nền dự án'
#Category_To_Study=''
#Field_To_Groupby='StreetName'

#city_name=""
#district_name="Xuyên Mộc"
#Street_To_Study=''
#Category_To_Study='Bán đất'
#Category_To_Study='Bán đất nền dự án'
#Category_To_Study=''
#Field_To_Groupby='WardName'


#city_name="Bà Rịa Vũng Tàu"
#district_name="Xuyên Mộc"
#Street_To_Study=''
#Category_To_Study='Bán đất'
#Category_To_Study='Bán đất nền dự án'
#Category_To_Study=''
#Field_To_Groupby='ProjectName'
#Field_To_Groupby='StreetName'

#district_name="Quận 9"
#district_name="Tân Bình"
#district_name="Quận 12"
#Street_To_Study='Nguyễn Ảnh Thủ'
#Category_To_Study='Bán nhà riêng'


city_name="Hà Nội"
district_name="Hoàn Kiếm"
#district_name="Quận 2"
Category_To_Study='Bán nhà mặt phố'
Field_To_Groupby='WardName' #WardName
#Street_To_Study=""

#city_name="Đồng Nai"
#district_name="Biên Hòa"
#city_name="Long An"
#district_name="Cần Giuộc"

#Category_To_Study='Bán đất'
#Field_To_Groupby='StreetName' #WardName
#Street_To_Study=""

#Category_To_Study='Bán đất'
#Category_To_Study='Bán đất nền dự án'

#district_name="Phú Nhuận"
#district_name="Tân Bình"
#district_name="Quận 12"
#Street_To_Study='Nguyễn Ảnh Thủ'


#Category_To_Study='Bán nhà riêng'
#Street_To_Study='Lê Văn Sỹ'
#Field_To_Groupby='StreetName'

#city_name="Hà Nội"
#district_name="Hoàn Kiếm"
#Category_To_Study='Bán căn hộ chung cư'
#Category_To_Study='Bán nhà riêng'
#Field_To_Groupby='WardName'
#Field_To_Groupby='StreetName'
#Street_To_Study="Lý Nam Đế"

#Category_To_Study='Bán nhà mặt phố'
#Field_To_Groupby='StreetName'

#Field_To_Groupby='WardName'
#Field_To_Groupby='StreetName'

#Category_To_Study='Bán căn hộ chung cư'
#Field_To_Groupby='ProjectName'

#city_name="Hà Nội"
#district_name="Ba Đình"

#Category_To_Study='Bán nhà riêng'
#Field_To_Groupby='StreetName'

#Category_To_Study='Bán nhà mặt phố'
#Field_To_Groupby='StreetName'
#Field_To_Groupby='WardName'

Output_to_All_Category=False
Output_to_All_District=False

#Category_To_Study='Bán căn hộ chung cư'
#Field_To_Groupby='ProjectName'

#city_name="Bà Rịa Vũng Tàu"
#district_name="Vũng Tàu"
#Category_To_Study='Bán căn hộ chung cư'
#Field_To_Groupby='ProjectName'


#Category_To_Study='Bán nhà mặt phố'
#Field_To_Groupby='WardName'

#district_name="Tân Bình"

#Category_To_Study='Bán căn hộ chung cư'
#Field_To_Groupby='ProjectName'

#city_name="Khánh Hòa"
#district_name="Nha Trang"

#Category_To_Study='Bán đất nền dự án'
#Field_To_Groupby='ProjectName'

#Category_To_Study='Bán nhà riêng'
#Field_To_Groupby='StreetName'
#Field_To_Groupby='WardName'

#Category_To_Study='Bán nhà mặt phố'
#Field_To_Groupby='StreetName'
#Field_To_Groupby='WardName'

"""# Verifying Format DateTime and Data

Testing if Input Data has been formateed
"""

def format_date(df):
    '''
    This function is used to format date for dataframe

    Inputs:
        -- df: pandas.core.frame.DataFrame
               dataframe which will be formated date

    Output:
        -- original dataframe but formated date
    '''

    # Return df if df has no 'EndDate' or 'StartDate' column
    if ('EndDate' not in df) or ('StartDate' not in df):
        return df

    df['EndDate'] = pd.to_datetime(df['EndDate'])
    df['StartDate'] = pd.to_datetime(df['StartDate'])

    return df

def format_price(df):
    '''
    This function is used to format coordinate to float64 for dataframe

    Inputs:
        -- df: pandas.core.frame.DataFrame
               dataframe which will be formated coordinate

    Output:
        -- original dataframe but formated coordinate
    '''

    # Return df if df has no 'Lat' or 'Lng' column
    if ('Price' not in df):
        return df

    df['Price'] = pd.to_numeric(df['Price'],errors='coerce')

    return df

def TestingInputData(df):
  #Start Date

  bl_startdate= isinstance(df.loc[0,'StartDate'],np.datetime64)
  bl_enddate=isinstance(df.loc[0,'EndDate'],np.datetime64)
  bl_lat=isinstance(df.loc[0,'Lat'],np.float64)
  bl_lng=isinstance(df.loc[0,'Lng'],np.float64)

  bl_price=isinstance(df.loc[0,'Price'],np.float64)

  if not bl_startdate:
    print('Start Date need be formated')

  if  not bl_enddate:
    print('End Date need be formated')

  if  not bl_lat:
    print('Lat need be formated')

  if  not bl_lng:
    print('Longtitude need be formated')

  if  not bl_price:
    print('Price need be formated')

  bl_inputdata=bl_startdate and bl_enddate and bl_lat and bl_lng and bl_price
  if bl_inputdata:
    print("Success DataReadiness")
  else:
    print("Try to format data again")
  
  return bl_inputdata

"""#Inport data from CSV file - Output"""

def Import_Data(city_name,district_name):
  filename_to_study='/content/drive/My Drive/12.Vietnam Stock Analysts - Quantum Equity Research/Real Estate/'+city_name+'_'+district_name+'_new'
  #filename_to_study='/content/drive/My Drive/12.Vietnam Stock Analysts - Quantum Equity Research/Real Estate/Hồ Chí Minh_Quận 2_new'

  df_main = pd.read_csv(filename_to_study+'.csv')
  if not TestingInputData(df_main):
    format_date(df_main)
    format_price(df_main)
  print('Import Data for ',city_name,' ',district_name)
  df=df_main[df_main['Category']=='Bán'].copy()
  
  df_rent=df_main[df_main['Category']=='Cho thuê'].copy()

  print('Formated Data Loaded')
  return df_main,df,df_rent,filename_to_study

df_main,df,df_rent,filename_to_study=Import_Data(city_name,district_name)

df_main.info()

df_main,df,df_rent,filename_to_study = Import_Data(city_name,district_name)

df_main.info()

df[df['CateName']=='Bán đất'].head()

df_main['SaleUnitPrice'].describe()

df.info()

"""#1. Understanding about Posting
Understanding Nature of Posts - ie Category Selling, What is the number of posts per each categories (Apartment, Lands,....)

If we understand - for example trends in Posting (in term of percentage, per month, we can see the trends what kinds of assets people interest most - following trends)

##Functions for understanding Category of Selling posting
"""

def Create_Category_Counts_DataFrame(df):
  cate_counts=df['CateName'].value_counts()
  cate_counts_df=pd.DataFrame(cate_counts)
  cate_counts_df=cate_counts_df.head(5)
  return cate_counts_df

def Create_Category_Counts_Series(df):
  cate_counts=df['CateName'].value_counts()
  return cate_counts

def Draw_Bar_Chart_Posts_By_Category(df):
  cate_counts_df=Create_Category_Counts_DataFrame(df)
  cate_counts_df=cate_counts_df.head(5)
  #Ve hinh category
  cate_counts_df.plot(kind='bar')
  plt.show()

"""## Draw Bar Charts for Posts by Category"""

Draw_Bar_Chart_Posts_By_Category(df)

"""## Pie charts"""

def Draw_Pie_Chart_Post(df,city_name,district_name):
  cate_counts_df=Create_Category_Counts_DataFrame(df)
  explode = (0, 0.1, 0.1, 0.2,0)  # only "explode" the 2nd slice (i.e. 'Hogs')
  fig1, ax1 = plt.subplots()
  ax1.pie(cate_counts_df.values,explode=explode, labels=cate_counts_df.index, autopct='%1.1f%%',
        shadow=True, startangle=0)
  ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
  ax1.set_title(city_name+' '+district_name,loc='Left')
  plt.show()

Draw_Pie_Chart_Post(df,city_name,district_name)

"""##Create Area -Line Chart following Month"""

#Create a DataFrame with grouping following monthly the categories
def CreateCategorySummarybyMonth(df):
  summary=pd.DataFrame()
  cate_counts=Create_Category_Counts_Series(df)
  for i in range(len(cate_counts)):
    post=df[df['CateName']==cate_counts.index[i]].copy()
    post.set_index(keys='StartDate',inplace=True)
    summary[cate_counts.index[i]] = post.EndDate.resample('M').count()
  return summary

def Draw_Category_SummarybyMonth(df):
  sum=CreateCategorySummarybyMonth(df)
  cate_counts=Create_Category_Counts_Series(df)
  ax = plt.gca() #get current axi
  sum.plot(y=cate_counts.index[0],kind='line',ax=ax)
  sum.plot(y=cate_counts.index[1],kind='line',color='red',ax=ax)
  sum.plot(y=cate_counts.index[2],kind='line',color='green',ax=ax)
  sum.plot(y=cate_counts.index[3],kind='line',color='black',ax=ax)
  plt.show()

Draw_Category_SummarybyMonth(df)

Draw_Category_SummarybyMonth(df_rent)

def Draw_Posting_about_Category_Month(df,Category_To_Study):
  sell_land_summary=pd.DataFrame()
  sell_land_post=df[df['CateName']==Category_To_Study]
  sell_land_post.set_index(keys='StartDate',inplace=True)
  #sell_land_post.index
  sell_land_summary[Category_To_Study] = sell_land_post.EndDate.resample('M').count()
  sell_land_summary.plot()
  plt.show()

Draw_Posting_about_Category_Month(df,Category_To_Study='Bán căn hộ chung cư')

"""#Understanding about Lending"""

df_rent.dtypes

df_rent[['Description','Area','ProjectName','Address','HouseNumber','HouseLevel','StreetName','WardName','CateName','Price','SaleUnitPrice','RentPrice']]

groupbyrent=df_rent[df_rent.StartDate>='2019'].groupby('ProjectName').RentPrice.median()
groupbyrent=groupbyrent.sort_values(ascending=False)
groupbyrent.head(20)

"""#2. Understanding Statistics - Relationship between fields

"""

df.dtypes

df[['Price','PriceLevel','UnitPrice','SaleUnitPrice']].head(20)
#df[].dropna(inplace=True)

df[['Price','UnitPrice','PriceLevel','Area','AreaLevel','WardId','StreetId','SaleUnitPrice','RentPrice','Lat','Lng']].corr()

sns_df=df[df['SaleUnitPrice']<100]
sns.boxplot(x="CateName",y="SaleUnitPrice",data=sns_df,)

type_realestate=set(df['CateName'])

print(type_realestate)

category_realestate=df.groupby(['CateName']).count()

print(category_realestate)

"""#3. Phân tích dữ liệu về một loại hình theo Category
VD: Theo Chung Cư
    Theo Bán nhà phố...

##Thông tin chung về DataFrame về dữ liệu bất động sản quan tâm
"""

def Verify_Wards_Name(df,Category_To_Study='Bán nhà riêng',Field_To_Groupby='WardName'):
  #Category_To_Study='Bán nhà riêng'
  #Field_To_Groupby='WardName'
  chungcu=df[df.CateName==Category_To_Study].copy()

  tenchungcu=pd.DataFrame(set(chungcu[Field_To_Groupby]))
  print(Category_To_Study)
  print("Tổng số:",len(tenchungcu))
  print(tenchungcu)
  #tenchungcu.to_csv()

def Create_Data_By_Category(df,Category_To_Study):
  Verify_Wards_Name(df,Category_To_Study,Field_To_Groupby)
  return df[df.CateName==Category_To_Study].copy()



"""## Theo dõi giá trung bình ở các loại hình bất động sản (đất, chung cư, nhà riêng...)"""

#Create a DataFrame with calculating Average Price following monthly the categories
def CreateAppartmentProjectSummarybyMonth_Median(df,Field_To_Groupby):
  summary=pd.DataFrame()
  tenchungcu=set(df[Field_To_Groupby])

  for sChungcu in tenchungcu:
    post=df[df[Field_To_Groupby]==sChungcu].copy()
    post.set_index(keys='StartDate',inplace=True)
    resample_series= post.SaleUnitPrice.resample('M').mean()
    resample_df=pd.DataFrame(resample_series)
    resample_df.columns=[sChungcu]
    summary = pd.concat([summary, resample_df], axis=1) 
  summary['Average Unit Price']=summary.median(axis=1)
  return summary

#Create a DataFrame with calculating Average Price following monthly the categories
def CreateAppartmentProjectSummarybyYear_Median(df,Field_To_Groupby):
  summary=pd.DataFrame()
  tenchungcu=set(df[Field_To_Groupby])
  for sChungcu in tenchungcu:
    post=df[df[Field_To_Groupby]==sChungcu].copy()
    post.set_index(keys='StartDate',inplace=True)
    resample_series= post.SaleUnitPrice.resample('Y').median()
    resample_df=pd.DataFrame(resample_series)
    resample_df.columns=[sChungcu]
    summary = pd.concat([summary, resample_df], axis=1) 

  return summary

def To_CSV_Summary_Month(chungcu,Category_To_Study,Field_To_Groupby):
  summary_apartment_project=CreateAppartmentProjectSummarybyMonth_Median(chungcu,Field_To_Groupby)
  filename_month=filename_to_study+'_'+Category_To_Study+'_'+Field_To_Groupby+'_month.csv'
  print('Output to file '+filename_month)
  summary_apartment_project.to_csv(filename_month,encoding='utf-8-sig')
  return summary_apartment_project

def To_CSV_Summary_Year(chungcu,Category_To_Study,Field_To_Groupby):
  summary_apartment_project_year=CreateAppartmentProjectSummarybyYear_Median(chungcu,Field_To_Groupby)
  summary_apartment_project_year=summary_apartment_project_year.transpose()
  if '2019-12-31' in summary_apartment_project_year.columns:
    # Sort theo giá cuối 2019
    summary_apartment_project_year=summary_apartment_project_year.sort_values(['2019-12-31'],ascending=False)
    #summary_apartment_project_year.head()
    filename_year_summerize=filename_to_study+'_'+Category_To_Study+'_'+Field_To_Groupby+'_year_summary.csv'
    print('Output to file '+filename_year_summerize)
    summary_apartment_project_year.to_csv(filename_year_summerize,encoding='utf-8-sig')
    return summary_apartment_project_year

def To_Excel_Summary_Year(writer,df,Category_To_Study,Field_To_Groupby):
  #1. Create data by Category to study
  chungcu=Create_Data_By_Category(df,Category_To_Study)

  #2. Create Year Summary - grouby Field_To_GroupBy (Ward, Project Name, Street...)
  summary_apartment_project_year=CreateAppartmentProjectSummarybyYear_Median(chungcu,Field_To_Groupby)
  summary_apartment_project_year=summary_apartment_project_year.transpose()
  if '2019-12-31' in summary_apartment_project_year.columns:
    # Sort theo giá cuối 2019
    summary_apartment_project_year=summary_apartment_project_year.sort_values(['2019-12-31'],ascending=False)
    #summary_apartment_project_year.head()
    sheet_name=Category_To_Study+'_'+Field_To_Groupby
    print('Output to sheet '+sheet_name)    
    
    #3. Output to Excel Sheet
    summary_apartment_project_year.to_excel(writer,sheet_name=sheet_name)
    return summary_apartment_project_year

def To_CSV_Summary_Year_StreetName(chungcu,Category_To_Study,Field_To_Groupby,Street_To_Study):
  chungcu=chungcu[chungcu['StreetName']==Street_To_Study]
  summary_apartment_project_year=CreateAppartmentProjectSummarybyYear_Median(chungcu,Field_To_Groupby)
  summary_apartment_project_year=summary_apartment_project_year.transpose()
  # Sort theo giá cuối 2019
  if '2019-12-31' in summary_apartment_project_year.columns:
    summary_apartment_project_year=summary_apartment_project_year.sort_values(['2019-12-31'],ascending=False)
    #summary_apartment_project_year.head()
    filename_year_summerize=filename_to_study+'_'+Category_To_Study+'_'+Field_To_Groupby+'_'+Street_To_Study+'_year_summary.csv'
    print('Output to file '+filename_year_summerize)
    summary_apartment_project_year.to_csv(filename_year_summerize,encoding='utf-8-sig')
    return summary_apartment_project_year

"""Output to CSV File for Summery of Category following by Groupby Fields"""

def Study_Category_Field_To_Groupby(chungcu):
  summary_apartment_project=To_CSV_Summary_Month(chungcu,Category_To_Study,Field_To_Groupby)
  summary_apartment_project_year=To_CSV_Summary_Year(chungcu,Category_To_Study,Field_To_Groupby)
  if Street_To_Study is not "":
    To_CSV_Summary_Year_StreetName(chungcu,Category_To_Study,Field_To_Groupby,Street_To_Study)
 
  plt.plot(summary_apartment_project.index.values,summary_apartment_project['Average Unit Price'])
  plt.ylabel("Triệu/m2")
  plt.title(city_name+' '+district_name+': Giá Trung Bình '+ Category_To_Study)
  plt.show()

def Excel_Study_All_Category(df,city_name,district_name):
  #1. Xác định Output folder ra ngoài
  folder_to_study='/content/drive/My Drive/12.Vietnam Stock Analysts - Quantum Equity Research/Real Estate/'
  folder_to_study=folder_to_study+city_name+'/'
  folder = pathlib.Path(folder_to_study)
  if not folder.exists():
    folder.mkdir(parents=True, exist_ok=True)   

  #summary_apartment_project=To_CSV_Summary_Month(chungcu,Category_To_Study,Field_To_Groupby)
  excel_file=folder_to_study+city_name+'_'+district_name+'_analysis.xlsx'
  file = pathlib.Path(excel_file)

  if file.exists():
    print(excel_file+" has existed")
    return

  writer = pd.ExcelWriter(excel_file, engine='xlsxwriter')

  #1. Output following each category + field to groupby
  Category_To_Study='Bán đất'
  Field_To_Groupby='WardName'
  Street_To_Study=""

  summary_apartment_project_year=To_Excel_Summary_Year(writer,df,Category_To_Study,Field_To_Groupby)

  Category_To_Study='Bán đất nền dự án'
  Field_To_Groupby='WardName'
  summary_apartment_project_year=To_Excel_Summary_Year(writer,df,Category_To_Study,Field_To_Groupby)

  Category_To_Study='Bán nhà mặt phố'
  Field_To_Groupby='WardName'
  summary_apartment_project_year=To_Excel_Summary_Year(writer,df,Category_To_Study,Field_To_Groupby)
  
  Category_To_Study='Bán nhà riêng'
  Field_To_Groupby='WardName'
  summary_apartment_project_year=To_Excel_Summary_Year(writer,df,Category_To_Study,Field_To_Groupby)

  Category_To_Study='Bán đất'
  Field_To_Groupby='StreetName'
  summary_apartment_project_year=To_Excel_Summary_Year(writer,df,Category_To_Study,Field_To_Groupby)

  Category_To_Study='Bán đất nền dự án'
  Field_To_Groupby='ProjectName'
  summary_apartment_project_year=To_Excel_Summary_Year(writer,df,Category_To_Study,Field_To_Groupby)

  Category_To_Study='Bán nhà riêng'
  Field_To_Groupby='StreetName'
  summary_apartment_project_year=To_Excel_Summary_Year(writer,df,Category_To_Study,Field_To_Groupby)

  Category_To_Study='Bán nhà mặt phố'
  Field_To_Groupby='StreetName'
  summary_apartment_project_year=To_Excel_Summary_Year(writer,df,Category_To_Study,Field_To_Groupby)

  Category_To_Study='Bán căn hộ chung cư'
  Field_To_Groupby='ProjectName'
  summary_apartment_project_year=To_Excel_Summary_Year(writer,df,Category_To_Study,Field_To_Groupby)

  # Close the Pandas Excel writer and output the Excel file.
  writer.save()

def Excel_Study_Province(city):
   #Get district of the city
  tinhtp="/content/drive/My Drive/12.Vietnam Stock Analysts - Quantum Equity Research/Real Estate/tinh_tp_danso_matdo.csv" #(Đọc thông tin Tỉnh/TP/Quận)
  df_city = pd.read_csv(tinhtp)
  
  #number_of_province=len(set(df_city['ProvinceName']))
  list_of_district=list(set(df_city[df_city['ProvinceName']==city]['DistrictName'])) #list of district of a specific city or province
  number_of_district=len(list_of_district)

  #print("So tinh thanh",len(list_of_district))
  for i in range(number_of_district):
    district_name=list_of_district[i]
    df_main,df,df_rent,filename_to_study=Import_Data(city,district_name)
    print('Output to Excel file of ',city,' ',district_name)
    Excel_Study_All_Category(df,city,district_name)

    #ExportToCSVFile_CityDistrict(city,district_name,filename)
    #print(city,"",district_name)

#Study_Category_Field_To_Groupby(chungcu)
#
#Excel_Study_Province(city_name)
#Excel_Study_All_Category(df,filename_to_study)

"""## GroupBy Examples - chung cu 2019

Group By examples 

"""

chungcu=Create_Data_By_Category(df,Category_To_Study)
chungcu_2019=chungcu[chungcu["StartDate"]>='2019']
chungcu_2019=chungcu_2019[chungcu_2019["StartDate"]<'2020']

chungcu_2019.describe()

chungcu_2019.info()

"""#Contact Mobile - Analysis of the most post by Contact"""

contact_2019=chungcu_2019.groupby(['ContactMobile'],as_index=True).count()

chungcu_2019_group=chungcu_2019.groupby([Field_To_Groupby],as_index=True).median()

chungcu_2019_group

"""##Analysis Apartment Project in 2019"""

StartDate_to_Study='2019'
EndDate_to_Study='2020'
pivot_2019=chungcu[[Field_To_Groupby,'Address','StartDate','Price','UnitPrice']]
pivot_2019=pivot_2019[pivot_2019['StartDate']>=StartDate_to_Study]
pivot_2019=pivot_2019[pivot_2019['StartDate']<EndDate_to_Study]
pivot_2019.head()

pv=pivot_2019.groupby(Field_To_Groupby).StartDate.count() #so luong post

pv.sort_values(ascending=False)

#pv.to_csv(('/content/drive/My Drive/12.Vietnam Stock Analysts - Quantum Equity Research/Real Estate/Phan tich BDS - Data Analyst/chungcu2019_years.csv'))

"""## Value **Counts**"""

chungcu_2019.describe()

chungcu_2019_counts=chungcu_2019.groupby(Field_To_Groupby).agg(['count','median','max','min'])

len(chungcu_2019_counts)

"""## Visualisation

## Top Chung Cu theo số post
"""

chungcu_2019_counts=chungcu_2019[Field_To_Groupby].value_counts()
top_chungcu_2019=pd.DataFrame(data=chungcu_2019_counts[:20])
top_chungcu_2019.rename(columns={Field_To_Groupby:'Number of Posts'},inplace=True)
top_chungcu_2019.head(20)
toplistchungcu2019=list(top_chungcu_2019.index)
top_chungcu_2019.plot(kind='bar',title=city_name+' '+district_name+':'+Category_To_Study)
plt.show()
#top_chungcu_2019.iloc[0]

#samplechungcu2019=chungcu_2019.head(1000)

samplechungcu2019=pd.DataFrame()
for i in range(0,len(toplistchungcu2019)):
  sample=chungcu_2019[chungcu_2019['ProjectName']==toplistchungcu2019[i]]
  samplechungcu2019=pd.concat([samplechungcu2019,sample])
#samplechungcu2019=samplechungcu2019[samplechungcu2019['UnitPrice']<60]

"""## Using Folium library for displaying some areas of apartments projects"""

chungcu_2019_group.head()

chungcu_2019_set_name=set(chungcu_2019_group.index)
chungcu_2019_set_name

# import folium package 
import folium
import folium.map
import folium.features
# Map method of folium return Map object 
  
feature_group=folium.map.FeatureGroup()

for chungcu_item in chungcu_2019_set_name:
  lat=chungcu_2019_group.loc[chungcu_item,['Lat']][0]
  lng=chungcu_2019_group.loc[chungcu_item,['Lng']][0]
  if (not math.isnan(lat)) and (not math.isnan(lng)):
    name=chungcu_item+":"+str(round(chungcu_2019_group.loc[chungcu_item,['SaleUnitPrice']][0],1))+" mil/m2"

    my_map1 = folium.Map(location = [lat,lng],zoom_start = 14 ) 
    feature_group.add_child(
      folium.CircleMarker([lat,lng],radius=10,color='Red',fillcolor='Red')
    )
    #feature_group.add_child(folium.Marker([lat,lng],popup=folium.Popup(html=html_name)))
    feature_group.add_child(folium.Marker([lat,lng],tooltip=folium.Tooltip(name)))

# save method of Map object will create a map 

my_map1.add_child(feature_group)
my_map1

my_map1

"""#Forecast Time-Series using LSTM model with Keras Library"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import models

import math
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

chungcu=Create_Data_By_Category(df,Category_To_Study)
forecast_data=CreateAppartmentProjectSummarybyMonth_Median(chungcu,Field_To_Groupby)

dataframe=forecast_data[['Average Unit Price']] #Safira Khang Điền
#dataframe=forecast_data[['Safira Khang Điền']]
dataframe=dataframe.dropna()

dataframe.info()

dataframe.describe()

dataframe.head()

plt.plot(dataframe)
plt.show()

# fix random seed for reproducibility
np.random.seed(7)

dataset = dataframe.values
dataset = dataset.astype('float32')

# normalize the dataset
scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(dataset)

#type(dataset)

# split into train and test sets
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]
print(len(train), len(test))

"""## Create a dataset matrix"""

# convert an array of values into a dataset matrix
def create_dataset(dataset, look_back=1):
	dataX, dataY = [], []
	for i in range(len(dataset)-look_back-1):
		a = dataset[i:(i+look_back), 0]
		dataX.append(a)
		dataY.append(dataset[i + look_back, 0])
	return np.array(dataX), np.array(dataY)

# reshape into X=t and Y=t+1
look_back = 1
window_size=look_back
train_X, train_Y = create_dataset(train, look_back)
test_X, test_Y = create_dataset(test, look_back)

print("Original training data shape:")
print(train_X.shape)

# Reshape the input data into appropriate form for Keras.
train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))
test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))
print("New training data shape:")
print(train_X.shape)

train_X

"""## Fit model - Create LSTM model"""

def fit_model(train_X, train_Y, window_size = 1):
    model = tf.keras.Sequential()
    
    model.add(LSTM(64, 
                   input_shape = (1, window_size)))
    
    model.add(Dense(1))
    model.compile(loss = "mean_squared_error", 
                  optimizer = "adam")
    model.fit(train_X, 
              train_Y, 
              epochs = 100, 
              batch_size = 1, 
              verbose = 2)
    
    return(model)

# Fit the first model.
model1 = fit_model(train_X, train_Y, window_size)

"""## Prediction in Test"""

def predict_and_score(model, X, Y):
    # Make predictions on the original scale of the data.
    pred = scaler.inverse_transform(model.predict(X))
    # Prepare Y data to also be on the original scale for interpretability.
    orig_data = scaler.inverse_transform([Y])
    # Calculate RMSE.
    score = math.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))
    return(score, pred)

rmse_train, train_predict = predict_and_score(model1, train_X, train_Y)
rmse_test, test_predict = predict_and_score(model1, test_X, test_Y)

print("Training data score: %.2f RMSE" % rmse_train)
print("Test data score: %.2f RMSE" % rmse_test)

"""##Plotting original data, predictions, and forecast"""

# Start with training predictions.
train_predict_plot = np.empty_like(dataset)
train_predict_plot[:, :] = np.nan
train_predict_plot[window_size:len(train_predict) + window_size, :] = train_predict

# Add test predictions.
test_predict_plot = np.empty_like(dataset)
test_predict_plot[:, :] = np.nan
test_predict_plot[len(train_predict) + (window_size * 2) + 1:len(dataset) - 1, :] = test_predict

# Create the plot.
plt.figure(figsize = (15, 5))
plt.plot(scaler.inverse_transform(dataset), label = "True value")
plt.plot(train_predict_plot, label = "Training set prediction")
plt.plot(test_predict_plot, label = "Test set prediction")
plt.xlabel("Months")
plt.ylabel("Price")
plt.title(city_name+' '+district_name+':'+Category_To_Study+ ' '+Field_To_Groupby+" so sánh vs. training / test")
plt.legend()
plt.show()